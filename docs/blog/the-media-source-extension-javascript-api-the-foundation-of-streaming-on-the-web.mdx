![](https://uploads-ssl.webflow.com/6143afec68f555387049efb3/63dd7cbe1b2429efebda4190_segments_3dee7b8cfb581c8d69adc424e23919b5_2000.jpeg)
"video; javascript-8"
# The Media Source Extension <> JavaScript API: The foundation of streaming on the web
> Wed Apr 05 2023 16:53:15 GMT+0000 (Coordinated Universal Time)
<p>The streaming universe is booming.<p.new.line><p>Since its inception way back in 2013, influential companies like Netflix, Amazon and Apple have poured millions of dollars into creating new TV shows, movies and other video content. Over the past decade, many business areas have been leveraged by this unique ecosystem, including tech. Because distributing video is challenging and costly, the tech industry has been tasked with making it faster, cheaper and easier to stream content. As a result, the way we stream video on the web is vastly different than it was a decade ago.<p.new.line><p>Back in the day, we relied on external plugins in browsers to play videos, like Microsoft Silverlight (2007) and Adobe Flash Player (1996).<p.new.line><p>They were the first solutions for playing videos on the web, but they quickly ran into trouble because of many security issues in their source code that attackers leveraged, among other technical limitations shown by the growing demand for video content.<p.new.line><p>In January 2013, the World Wide Web Consortium (W3C) wrote a new standard to address these challenges: <u><a href="https://www.w3.org/TR/2013/WD-media-source-20130129/" target="_blank" rel="noopener noreferrer">Media Source Extensions</a></u> (MSE).<p.new.line><p>MSE aimed to be incorporated into the HTML5 standard. It set specifications for the byte streams and video/audio codecs supported on web browsers through video and audio HTML5 tags.<p.new.line><p>In September 2013, Youtube was one of the first video pioneers to use MSE.<p.new.line><h2 id="8ibcf">The MSE advantage<h2.new.line><p>Handling video data on the web is challenging.<p.new.line><p>Have you ever tried to share a big video file over the internet? Not many free and reliable solutions exist, as storing big data is generally very costly and very inconvenient to download.<p.new.line><p>As you know, requesting a whole movie bigger than 1.5GB on a web browser is not exactly efficient.<p.new.line><p>That&#x27;s when byte streams begin to take shape. MSE and HTTP form a great team when it comes to downloading part of a file. Indeed, a few streaming standards have emerged— like Microsoft Smooth Streaming, DASH and HLS— to propose a solution that would leverage these two APIs to make transporting video content on the web much more efficient than it used to be. These standards permit requesting a small chunk of video data, usually 2 seconds at a time.<p.new.line><p>This technique is very efficient because you don&#x27;t have to download the entire video, but only what you really consume; there’s no point in downloading the complete video data when you can only watch one part of it at a time.<p.new.line><p>Here is a small schema explaining the process that most streaming companies use to transport video data to your TV, phone or computer.<p.new.line><figure class="w-richtext-figure-type-image w-richtext-align-center" data-rt-type="image" data-rt-align="center"><div><img alt="A diagram of how video players interact with servers." src="https://uploads-ssl.webflow.com/6143afec68f555387049efb3/63176af152c14e4e9218944c_ScreenShot2022-09-02at2_03_43PM_b5158075f03068fd82fbf31e5ccd5143_800.png"><div.new.line><figure.new.line><h2 id="17n2f">How it works<h2.new.line><p>Based on the schema above, we can see that the server stores the various pieces that the client needs to play a video.<p.new.line><p>On one hand, we have the segments, which are small chunks of a video (usually two seconds long). If we merge those two-second chunks, we have the whole video.<p.new.line><p>On the other hand, we have the manifest. This is our guide: it tells us where to find the video data on the server and what data is available. This could be in which quality the video is available or what audio and subtitle languages we can choose.<p.new.line><p>The manifest’s file follows different possible standards, the most common of which are the <u><a href="https://dashif.org/docs/DASH-IF-IOP-v4.3.pdf" target="_blank" rel="noopener noreferrer">DASH</a></u> and <u><a href="https://developer.apple.com/streaming/" target="_blank" rel="noopener noreferrer">HLS</a></u> standards.<p.new.line><p>You can see <u><a href="https://mediahelper.vercel.app/manifest" target="_blank" rel="noopener noreferrer">here</a></u> what form the manifest could take depending on the standard it adopts.<p.new.line><p>It&#x27;s then the role of the application to decide what to download, depending on the user&#x27;s choice and internet conditions. For example, downloading 4K video segments may not be the best choice if the user&#x27;s internet access is limited, as 4K video segments are the heaviest.<p.new.line><p>The video player layer is responsible for requesting video segments from the server under the form of ArrayBuffer, a JavaScript type used to represent raw binary data.<p.new.line><p>Nowadays, manipulating binary data on the front end is not very common, but this is where MSE comes into play.<p.new.line><h2 id="92ts0">The MSE API<h2.new.line><h3 id="88v7p">The &lt;video/&gt; element<h3.new.line><figure class="w-richtext-figure-type-image w-richtext-align-center" data-rt-type="image" data-rt-align="center"><div><img alt="A flowchart of downloading a video element." src="https://uploads-ssl.webflow.com/6143afec68f555387049efb3/63176af252c14e032018945c_ScreenShot2022-09-02at2_05_38PM_5b2acc5ac487bb2370bf81647dda018d_800.png"><div.new.line><figure.new.line><p>The magic happens in the <u><a href="https://www.w3.org/TR/2011/WD-html5-20110113/video.html#attr-media-src" target="_blank" rel="noopener noreferrer">&lt;video/&gt; HTML5 element</a></u>. Many developers know that we have to specify a media element to the <code>src</code> attribute like so:<p.new.line><pre>&lt;video src=&quot;https://myvideo.com/birthday.mp4&quot;/&gt;</pre><p>But a few know that we can pass a URL that is directly linked to an object that lives in memory.<p.new.line><p>We achieve that thanks to the API: <p.new.line><pre>URL.createObjectURL(...)</pre><p>The URL will look like what we have below:<p.new.line><pre>const video = document.querySelector(&#x27;video&#x27;);<br>video.src = URL.createObjectURL(...);<br><br>//src=&quot;blob:&lt;https://www.youtube.com/8d195e98-26d6-4f01-8251-f1d1fabc2634&gt;&quot;</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=adb749911c" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><h3 id="205li">Media Source<h3.new.line><p>Now that we know that we can create a URL that is directly linked to an object, we will leverage the MediaSource API to create a <code>MediaSource</code> object connected to the <code>&lt;video/&gt;</code> element.<p.new.line><pre>const mediaSource = new MediaSource();<br>video.src = URL.createObjectURL(mediaSource);</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=2529488477" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><p>Until here, everything works fine, but nothing will happen as the <code>MediaSource</code> object isn’t filled with anything. It’s empty. We need to add video data.<p.new.line><p>This is when the <code>SourceBuffer</code> object is used.<p.new.line><h3 id="b0k5v">SourceBuffer<h3.new.line><p>The <code>SourceBuffer</code> object acts like an actual buffer. It&#x27;s a small object used to store data and could be represented like so:<p.new.line><figure class="w-richtext-figure-type-image w-richtext-align-center" data-rt-type="image" data-rt-align="center"><div><img alt="A visual representation of a loading buffer. " src="https://uploads-ssl.webflow.com/6143afec68f555387049efb3/63176af152c14e817418944b_ScreenShot2022-09-02at2_08_36PM_83ac7f4f7410f83c81ca7001f72fde29_800.png"><div.new.line><figure.new.line><p>We will store the two-second video segments we discussed earlier in this buffer.<p.new.line><p>A few methods live in the <code>MediaSource</code> instance. One of them is <code>addSourceBuffer</code>. This is the method that will create and add a <code>SourceBuffer</code> object to the <code>MediaSource</code>.<p.new.line><pre>const mimeCodec = &#x27;video/mp4; codecs=&quot;avc1.42E01E, mp4a.40.2&quot;&#x27;;<br>const bufferVideo = mediaSource.addSourceBuffer(mimeCodec);</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=37f44cad38" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><p>The <code>addSourceBuffer</code> methods take a single parameter that needs to be specified to tell the <code>SourceBuffer</code> the kind of data we will insert in the buffer.<p.new.line><p>In the video world, we compress and decompress video to transport it through the internet to gain in size, as we would do with a big file that we’ve zipped to make it easier to transport.<p.new.line><p>Multiple types of compression algorithms exist out there, but the most known in the industry are H264 (Advanced Video encoding) and its evolution, H265 (High-Efficiency Video Coding). H265 compresses twice as well for the same quality as H264. The decoding usually happens on the hardware side of the client you use to play the video (PC, Smartphone, Console…). As H265 is relatively new to the market, many hardware materials do not support this codec.<p.new.line><p>The MSE API provides a way to know if the codec you want to use is available, given your current hardware configuration.<p.new.line><pre>MediaSource.isTypeSupported(mimeCodec) // true or false</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=c0e14abd30" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><p>Here, <code>mimeCodec</code> is essential, because most of the time, you can’t push a different codec type on the same <code>SourceBuffer</code>. Before adding new data from a different codec, you must first call the <code>changeType</code> method on the <code>SourceBuffer</code>.<p.new.line><p>The codec is the program we name that encodes and decodes a data stream.<p.new.line><p>Finally, once we have our <code>SourceBuffer</code> instance, we can start adding actual video segments to the buffer we just created, thanks to the <code>appendBuffer(buf)</code> method on the <code>SourceBuffer</code> instance.<p.new.line><pre>const mimeCodec = &#x27;video/mp4; codecs=&quot;avc1.42E01E, mp4a.40.2&quot;&#x27;;<br>const bufferVideo = mediaSource.addSourceBuffer(mimeCodec);<br>bufferVideo.appendBuffer(buf)</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=582045b77b" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><p>Once the <code>videoElement</code> has enough data in the buffer to start playing the video, its property <code>readyState</code> will be superior or equal to 3. The <code>videoElement</code> can then trigger the <code>play</code> method.<p.new.line><h3 id="7akh0">Events<h3.new.line><p>The process of setting up these APIs is eventful. This means that most APIs should be called when an event has been sent to tell them that the API is ready to proceed further.<p.new.line><p>For instance, when we create a <code>MediaSource</code> instance, we can’t instantaneously use it, as it will be in the <u><a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaSource/readyState" target="_blank" rel="noopener noreferrer"><code>closed</code> state</a></u>:<p.new.line><pre>const mediaSource = new MediaSource()<br>console.log(mediaSource.readyState); // closed</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=ee584bbf87" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><p>We need to wait for the <code>MediaSource</code> to be in the <strong>open</strong> state.<p.new.line><pre>mediaSource.addEventListener(&#x27;sourceopen&#x27;, () =&gt; {<br> // The mediaSource is open and ready to receive a sourceBuffer <br>});</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=2670468443" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><p>The <code>SourceBuffer</code> object also produces many <u><a href="https://developer.mozilla.org/en-US/docs/Web/API/SourceBuffer#events" target="_blank" rel="noopener noreferrer">events</a></u>.<p.new.line><h3 id="5d2ek">Appending real data<h3.new.line><p>We now know how to append data, but how can we retrieve the data that we will send to the <code>SourceBuffer</code> we just created?<p.new.line><p>We will use the <code>responseType</code> property from the <code>XMLHttpRequest</code> API that tells the browser what kind of data we want back.<p.new.line><pre>const xhr = new XMLHttpRequest;<br>  xhr.open(&#x27;get&#x27;, url);<br>  xhr.responseType = &#x27;arraybuffer&#x27;;<br>  xhr.onload = () =&gt; {<br> // append the video segment to the buffer<br>  sourceBuffer.appendBuffer(xhr.response);<br>  };<br>  xhr.send();</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=b7834d8d23" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em><p.new.line><p>We set the <code>responseType</code> to <code>arraybuffer</code>, which acts like a binary JavaScript representation that contains the two-second video segment.<p.new.line><p>Once we request that data from the server, we can insert it inside the <code>SourceBuffer</code> object we created.<p.new.line><h2 id="ed266">Conclusion<h2.new.line><p>Since the first live-streamed concert in 1993, video has been a part of the internet. Since then, video has gained more and more traction, reaching incredible milestones and allowing internet companies to create entire businesses around video. For instance, in 2018,<a href="https://www.bbc.com/news/technology-45745362?ocid=socialflow_twitter" target="_blank" rel="noopener noreferrer"> <u>according to research from bandwidth management company Sandvine</u></a>, Netflix occupied 15% of worldwide internet traffic. There’s also the mastodon of video on the internet, YouTube, which accrues more than<a href="https://www.globalmediainsight.com/blog/youtube-users-statistics/" target="_blank" rel="noopener noreferrer"> <u>1 billion hours of watched content worldwide every day</u></a>.<p.new.line><p>From these success stories, it’s clear that the technical handling of video on the internet has required innovation. So many of these actors gathered to create new technologies of distribution to make it faster and less frustrating for users to consume video on the web.<p.new.line><p>Hence, MSE has evolved to be even more supported across different browsers and platforms. This article acts as an introduction to how prominent actors handle video on the web. However, video is more complex than we think, and many other factors should be considered in further articles.<p.new.line>\n\n    <figure data-rt-type="video" data-rt-align="center">\n    
The streaming universe is booming.
Since its inception way back in 2013, influential companies like Netflix, Amazon and Apple have poured millions of dollars into creating new TV shows, movies and other video content. Over the past decade, many business areas have been leveraged by this unique ecosystem, including tech. Because distributing video is challenging and costly, the tech industry has been tasked with making it faster, cheaper and easier to stream content. As a result, the way we stream video on the web is vastly different than it was a decade ago.
Back in the day, we relied on external plugins in browsers to play videos, like Microsoft Silverlight (2007) and Adobe Flash Player (1996).
They were the first solutions for playing videos on the web, but they quickly ran into trouble because of many security issues in their source code that attackers leveraged, among other technical limitations shown by the growing demand for video content.
In January 2013, the World Wide Web Consortium (W3C) wrote a new standard to address these challenges: <u><a href="https://www.w3.org/TR/2013/WD-media-source-20130129/" target="_blank" rel="noopener noreferrer">Media Source Extensions</a></u> (MSE).
MSE aimed to be incorporated into the HTML5 standard. It set specifications for the byte streams and video/audio codecs supported on web browsers through video and audio HTML5 tags.
In September 2013, Youtube was one of the first video pioneers to use MSE.
## The MSE advantage
Handling video data on the web is challenging.
Have you ever tried to share a big video file over the internet? Not many free and reliable solutions exist, as storing big data is generally very costly and very inconvenient to download.
As you know, requesting a whole movie bigger than 1.5GB on a web browser is not exactly efficient.
That&#x27;s when byte streams begin to take shape. MSE and HTTP form a great team when it comes to downloading part of a file. Indeed, a few streaming standards have emerged— like Microsoft Smooth Streaming, DASH and HLS— to propose a solution that would leverage these two APIs to make transporting video content on the web much more efficient than it used to be. These standards permit requesting a small chunk of video data, usually 2 seconds at a time.
This technique is very efficient because you don&#x27;t have to download the entire video, but only what you really consume; there’s no point in downloading the complete video data when you can only watch one part of it at a time.
Here is a small schema explaining the process that most streaming companies use to transport video data to your TV, phone or computer.
![](" src="https://uploads-ssl.webflow.com/6143afec68f555387049efb3/63176af152c14e4e9218944c_ScreenShot2022-09-02at2_03_43PM_b5158075f03068fd82fbf31e5ccd5143_800.p)
## How it works
Based on the schema above, we can see that the server stores the various pieces that the client needs to play a video.
On one hand, we have the segments, which are small chunks of a video (usually two seconds long). If we merge those two-second chunks, we have the whole video.
On the other hand, we have the manifest. This is our guide: it tells us where to find the video data on the server and what data is available. This could be in which quality the video is available or what audio and subtitle languages we can choose.
The manifest’s file follows different possible standards, the most common of which are the <u><a href="https://dashif.org/docs/DASH-IF-IOP-v4.3.pdf" target="_blank" rel="noopener noreferrer">DASH</a></u> and <u><a href="https://developer.apple.com/streaming/" target="_blank" rel="noopener noreferrer">HLS</a></u> standards.
You can see <u><a href="https://mediahelper.vercel.app/manifest" target="_blank" rel="noopener noreferrer">here</a></u> what form the manifest could take depending on the standard it adopts.
It&#x27;s then the role of the application to decide what to download, depending on the user&#x27;s choice and internet conditions. For example, downloading 4K video segments may not be the best choice if the user&#x27;s internet access is limited, as 4K video segments are the heaviest.
The video player layer is responsible for requesting video segments from the server under the form of ArrayBuffer, a JavaScript type used to represent raw binary data.
Nowadays, manipulating binary data on the front end is not very common, but this is where MSE comes into play.
## The MSE API
### The &lt;video/&gt; element
![](ps://uploads-ssl.webflow.com/6143afec68f555387049efb3/63176af252c14e032018945c_ScreenShot2022-09-02at2_05_38PM_5b2acc5ac487bb2370bf81647dda018d_800.p)
The magic happens in the <u><a href="https://www.w3.org/TR/2011/WD-html5-20110113/video.html#attr-media-src" target="_blank" rel="noopener noreferrer">&lt;video/&gt; HTML5 element</a></u>. Many developers know that we have to specify a media element to the <code>src</code> attribute like so:
e>&lt;video src=&quot;https://myvideo.com/birthday.mp4&quot;/&gt;</pre><p>But a few know that we can pass a URL that is directly linked to an object that lives in memory.
We achieve that thanks to the API: 
e>URL.createObjectURL(...)</pre><p>The URL will look like what we have below:
e>const video = document.querySelector(&#x27;video&#x27;);<br>video.src = URL.createObjectURL(...);<br><br>//src=&quot;blob:&lt;https://www.youtube.com/8d195e98-26d6-4f01-8251-f1d1fabc2634&gt;&quot;</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=adb749911c" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
### Media Source
Now that we know that we can create a URL that is directly linked to an object, we will leverage the MediaSource API to create a <code>MediaSource</code> object connected to the <code>&lt;video/&gt;</code> element.
e>const mediaSource = new MediaSource();<br>video.src = URL.createObjectURL(mediaSource);</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=2529488477" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
Until here, everything works fine, but nothing will happen as the <code>MediaSource</code> object isn’t filled with anything. It’s empty. We need to add video data.
This is when the <code>SourceBuffer</code> object is used.
### SourceBuffer
The <code>SourceBuffer</code> object acts like an actual buffer. It&#x27;s a small object used to store data and could be represented like so:
![](ttps://uploads-ssl.webflow.com/6143afec68f555387049efb3/63176af152c14e817418944b_ScreenShot2022-09-02at2_08_36PM_83ac7f4f7410f83c81ca7001f72fde29_800.p)
We will store the two-second video segments we discussed earlier in this buffer.
A few methods live in the <code>MediaSource</code> instance. One of them is <code>addSourceBuffer</code>. This is the method that will create and add a <code>SourceBuffer</code> object to the <code>MediaSource</code>.
e>const mimeCodec = &#x27;video/mp4; codecs=&quot;avc1.42E01E, mp4a.40.2&quot;&#x27;;<br>const bufferVideo = mediaSource.addSourceBuffer(mimeCodec);</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=37f44cad38" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
The <code>addSourceBuffer</code> methods take a single parameter that needs to be specified to tell the <code>SourceBuffer</code> the kind of data we will insert in the buffer.
In the video world, we compress and decompress video to transport it through the internet to gain in size, as we would do with a big file that we’ve zipped to make it easier to transport.
Multiple types of compression algorithms exist out there, but the most known in the industry are H264 (Advanced Video encoding) and its evolution, H265 (High-Efficiency Video Coding). H265 compresses twice as well for the same quality as H264. The decoding usually happens on the hardware side of the client you use to play the video (PC, Smartphone, Console…). As H265 is relatively new to the market, many hardware materials do not support this codec.
The MSE API provides a way to know if the codec you want to use is available, given your current hardware configuration.
e>MediaSource.isTypeSupported(mimeCodec) // true or false</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=c0e14abd30" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
Here, <code>mimeCodec</code> is essential, because most of the time, you can’t push a different codec type on the same <code>SourceBuffer</code>. Before adding new data from a different codec, you must first call the <code>changeType</code> method on the <code>SourceBuffer</code>.
The codec is the program we name that encodes and decodes a data stream.
Finally, once we have our <code>SourceBuffer</code> instance, we can start adding actual video segments to the buffer we just created, thanks to the <code>appendBuffer(buf)</code> method on the <code>SourceBuffer</code> instance.
e>const mimeCodec = &#x27;video/mp4; codecs=&quot;avc1.42E01E, mp4a.40.2&quot;&#x27;;<br>const bufferVideo = mediaSource.addSourceBuffer(mimeCodec);<br>bufferVideo.appendBuffer(buf)</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=582045b77b" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
Once the <code>videoElement</code> has enough data in the buffer to start playing the video, its property <code>readyState</code> will be superior or equal to 3. The <code>videoElement</code> can then trigger the <code>play</code> method.
### Events
The process of setting up these APIs is eventful. This means that most APIs should be called when an event has been sent to tell them that the API is ready to proceed further.
For instance, when we create a <code>MediaSource</code> instance, we can’t instantaneously use it, as it will be in the <u><a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaSource/readyState" target="_blank" rel="noopener noreferrer"><code>closed</code> state</a></u>:
e>const mediaSource = new MediaSource()<br>console.log(mediaSource.readyState); // closed</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=ee584bbf87" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
We need to wait for the <code>MediaSource</code> to be in the <strong>open</strong> state.
e>mediaSource.addEventListener(&#x27;sourceopen&#x27;, () =&gt; {<br> // The mediaSource is open and ready to receive a sourceBuffer <br>});</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=2670468443" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
The <code>SourceBuffer</code> object also produces many <u><a href="https://developer.mozilla.org/en-US/docs/Web/API/SourceBuffer#events" target="_blank" rel="noopener noreferrer">events</a></u>.
### Appending real data
We now know how to append data, but how can we retrieve the data that we will send to the <code>SourceBuffer</code> we just created?
We will use the <code>responseType</code> property from the <code>XMLHttpRequest</code> API that tells the browser what kind of data we want back.
e>const xhr = new XMLHttpRequest;<br>  xhr.open(&#x27;get&#x27;, url);<br>  xhr.responseType = &#x27;arraybuffer&#x27;;<br>  xhr.onload = () =&gt; {<br> // append the video segment to the buffer<br>  sourceBuffer.appendBuffer(xhr.response);<br>  };<br>  xhr.send();</pre><p><em><u><a href="https://3863d558-45a9-40e6-9dff-136019435fd6.pieces.cloud/?p=b7834d8d23" target="_blank" rel="noopener noreferrer">Click to save this command to Pieces</a></u></em>
We set the <code>responseType</code> to <code>arraybuffer</code>, which acts like a binary JavaScript representation that contains the two-second video segment.
Once we request that data from the server, we can insert it inside the <code>SourceBuffer</code> object we created.
## Conclusion
Since the first live-streamed concert in 1993, video has been a part of the internet. Since then, video has gained more and more traction, reaching incredible milestones and allowing internet companies to create entire businesses around video. For instance, in 2018,<a href="https://www.bbc.com/news/technology-45745362?ocid=socialflow_twitter" target="_blank" rel="noopener noreferrer"> <u>according to research from bandwidth management company Sandvine</u></a>, Netflix occupied 15% of worldwide internet traffic. There’s also the mastodon of video on the internet, YouTube, which accrues more than<a href="https://www.globalmediainsight.com/blog/youtube-users-statistics/" target="_blank" rel="noopener noreferrer"> <u>1 billion hours of watched content worldwide every day</u></a>.
From these success stories, it’s clear that the technical handling of video on the internet has required innovation. So many of these actors gathered to create new technologies of distribution to make it faster and less frustrating for users to consume video on the web.
Hence, MSE has evolved to be even more supported across different browsers and platforms. This article acts as an introduction to how prominent actors handle video on the web. However, video is more complex than we think, and many other factors should be considered in further articles.
